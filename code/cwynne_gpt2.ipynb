{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run once (may have to restart notebook)\n",
    "# !pip install tensorflow-gpu==1.15 --user # if you do not have a gpu remove -gpu \n",
    "# !pip install gpt-2-simple --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "is_local = True # change this if you are not loading a pretrained model locally\n",
    "if is_local:\n",
    "    # import tensorflow as tf\n",
    "    import sys\n",
    "    sys.path.insert(0, os.path.abspath('../../gpt-2-simple-0.7/gpt_2_simple'))\n",
    "    import gpt_2 as gpt2\n",
    "    local_checkpoint_dir = \"../../local_checkpoints\" # directory where local models are stored\n",
    "    local_model_name = 'model-100'\n",
    "else:\n",
    "    import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure gpu is recognized for significantly faster training\n",
    "\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"124M\"\n",
    "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
    "    print(f\"Downloading {model_name} model...\")\n",
    "    gpt2.download_gpt2(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"../data/\"\n",
    "\n",
    "dem_file_name = \"democrats_result.txt\"\n",
    "dem_sample_name = \"democrats_sample.txt\"\n",
    "dem_model_name = 'dem'\n",
    "\n",
    "rep_file_name = 'republican_result.txt'\n",
    "rep_sample_name = 'republican_sample.txt'\n",
    "rep_model_name = 'rep'\n",
    "\n",
    "both_file_name = 'both_result.txt'\n",
    "both_sample_name = 'both_sample.txt'\n",
    "both_model_name = 'both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading and writing sample files for each side\n",
    "\n",
    "# with open(dir_path+dem_file_name,'r') as demf:\n",
    "#     dem_data = demf.readlines(500000)\n",
    "# with open(dir_path+dem_sample_name,'w+') as dem_write:\n",
    "#     dem_write.writelines(dem_data)\n",
    "\n",
    "# with open(dir_path+rep_file_name,'r') as repf:\n",
    "#     rep_data = repf.readlines(500000)\n",
    "# with open(dir_path+rep_sample_name,'w+') as rep_write:\n",
    "#     rep_write.writelines(rep_data)\n",
    "\n",
    "# dem_data.extend(rep_data)\n",
    "# both_data = dem_data\n",
    "\n",
    "\n",
    "# with open(dir_path+both_file_name,'r') as bothf:\n",
    "#     both_data = bothf.readlines(100000)\n",
    "# with open(dir_path+both_sample_name,'w+') as both_write:\n",
    "#     both_write.writelines(both_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text file to train model on\n",
    "train_fp = dir_path + both_sample_name\n",
    "train_name = both_model_name\n",
    "results_fp = \"../results/\" + train_name + \"_generated.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint ../../local_checkpoints/both/model-100\n",
      "INFO:tensorflow:Restoring parameters from ../../local_checkpoints/both/model-100\n"
     ]
    }
   ],
   "source": [
    "# this cell takes the longest. Can only be run once without restarting the notebook\n",
    "sess = gpt2.start_tf_sess()\n",
    "if is_local:\n",
    "    gpt2.load_gpt2(sess, \n",
    "                   checkpoint=local_model_name, \n",
    "                   run_name=train_name, \n",
    "                   checkpoint_dir=local_checkpoint_dir)\n",
    "else:\n",
    "    gpt2.finetune(sess,\n",
    "                  train_fp,\n",
    "                  model_name=model_name,\n",
    "                  steps=100, # steps is max number of training steps\n",
    "                  restore_from='fresh', # makes sure model doesnt resume from previous trained model\n",
    "                  print_every=20, # only prints every 20 training steps,\n",
    "                  run_name=train_name # model name, so we can load different models locally\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt to generate response to, going to be a post/comment from the political discussion subreddits\n",
    "\n",
    "pre = \"After witnessing the heinous amount of police brutality in the US against POC, \\\n",
    "my partner and I have created some protest posters in response. We do not care about \\\n",
    "credit, just getting the message out there, so feel free to distribute however way you \\\n",
    "want, or make better versions yourself if you think it can be improved!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2.generate(sess, \n",
    "              temperature=.8, # uniqueness of the output (usually ranges from .5 to 2)\n",
    "              prefix=pre, # prompt\n",
    "              nsamples=5, # number of generated responses \n",
    "              length=400 # number of words (including prompt) per response\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2.generate_to_file(sess, \n",
    "                      destination_path=results_fp,\n",
    "                      temperature=.8, # uniqueness of the output (usually ranges from .5 to 2)\n",
    "                      prefix=pre, # prompt\n",
    "                      nsamples=5, # number of generated responses \n",
    "                      length=400 # number of words (including prompt) per response)\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
