{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run once (may have to restart notebook)\n",
    "# !pip install gpt-2-simple\n",
    "# !pip install tensorflow==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import gpt_2_simple as gpt2\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 124M model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 277Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:00, 6.36Mit/s]                                                   \n",
      "Fetching hparams.json: 1.05Mit [00:00, 391Mit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:21, 23.2Mit/s]                                  \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 285Mit/s]                                                \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 8.36Mit/s]                                                \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 8.25Mit/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "model_name = \"124M\"\n",
    "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
    "    print(f\"Downloading {model_name} model...\")\n",
    "    gpt2.download_gpt2(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"../data/\"\n",
    "dem_file_name = \"democrats_result.txt\"\n",
    "sample_dem_name = \"democrats_sample.txt\"\n",
    "# if not os.path.exists(dir_path):\n",
    "#     os.makedirs(dir_path)\n",
    "# if not os.path.isfile(dir_path + file_name):\n",
    "#     url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "#     data = requests.get(url)\n",
    "#     with open(dir_path + file_name, 'w') as f:\n",
    "#         f.write(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir_path + dem_file_name,'r') as f:\n",
    "    data = f.readlines(10000)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir_path + \"democrats_sample.txt\",'w+') as to_write:\n",
    "    to_write.writelines(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Loading checkpoint models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 599.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "dataset has 2348 tokens\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 | 110.97] loss=3.82 avg=3.82\n",
      "[2 | 221.97] loss=3.40 avg=3.61\n",
      "[3 | 330.37] loss=3.13 avg=3.45\n",
      "[4 | 432.48] loss=2.71 avg=3.26\n",
      "[5 | 537.99] loss=2.45 avg=3.09\n",
      "[6 | 648.59] loss=2.41 avg=2.98\n",
      "[7 | 755.09] loss=1.99 avg=2.83\n",
      "[8 | 866.86] loss=1.85 avg=2.71\n",
      "[9 | 983.01] loss=1.65 avg=2.58\n",
      "[10 | 1097.35] loss=1.37 avg=2.46\n",
      "[11 | 1206.88] loss=1.06 avg=2.32\n",
      "[12 | 1313.66] loss=1.24 avg=2.23\n",
      "[13 | 1418.23] loss=0.78 avg=2.11\n",
      "[14 | 1531.37] loss=0.59 avg=1.99\n",
      "[15 | 1636.30] loss=0.63 avg=1.90\n",
      "[16 | 1740.20] loss=0.19 avg=1.78\n",
      "[17 | 1861.55] loss=0.21 avg=1.68\n",
      "[18 | 1969.99] loss=0.55 avg=1.61\n",
      "[19 | 2074.67] loss=0.25 avg=1.54\n",
      "[20 | 2202.76] loss=0.33 avg=1.47\n",
      "[21 | 2315.74] loss=0.14 avg=1.40\n",
      "[22 | 2424.17] loss=0.17 avg=1.34\n",
      "[23 | 2529.85] loss=0.12 avg=1.28\n",
      "[24 | 2641.94] loss=0.10 avg=1.22\n",
      "[25 | 2754.66] loss=0.08 avg=1.17\n",
      "[26 | 2859.80] loss=0.04 avg=1.12\n",
      "[27 | 2963.81] loss=0.04 avg=1.08\n",
      "[28 | 3083.66] loss=0.05 avg=1.03\n",
      "[29 | 3187.97] loss=0.05 avg=1.00\n",
      "[30 | 3295.69] loss=0.04 avg=0.96\n",
      "[31 | 3403.11] loss=0.03 avg=0.92\n",
      "[32 | 3509.58] loss=0.03 avg=0.89\n",
      "[33 | 3615.02] loss=0.10 avg=0.86\n",
      "interrupted\n",
      "Saving checkpoint/run1/model-33\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.finetune(sess,\n",
    "              dir_path + sample_dem_name,\n",
    "              model_name=model_name,\n",
    "              steps=100)   # steps is max number of training steps\n",
    "\n",
    "gpt2.generate(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2.generate(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
